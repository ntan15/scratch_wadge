\pdfoutput=1

%\documentclass[preprint,10pt]{elsarticle}
\documentclass[preprint,10pt]{article}
%\documentclass[review]{siamart0216}
%\documentclass{siamart0216}

\usepackage{fullpage}
\usepackage[colorlinks=true]{hyperref}

\usepackage{amsmath,amssymb,amsfonts,amsthm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\theoremstyle{lemma}
\newtheorem{lemma}{Lemma}
\newtheorem*{remark}{Remark}
\theoremstyle{theorem}
\newtheorem{theorem}{Theorem}
\theoremstyle{assumption}
\newtheorem{assumption}{Assumption}

\usepackage[titletoc,toc,title]{appendix}

\usepackage{array} 
\usepackage{mathtools}
\usepackage{pdfpages}
\usepackage{bm}
\usepackage{bbm}

\usepackage{tikz}
\usepackage[normalem]{ulem}
\usepackage{hhline}

\usepackage{graphicx}
\usepackage{subfig}
\usepackage{color}

%% ====================================== graphics

\usepackage{pgfplots}
\usepackage{pgfplotstable}
\definecolor{markercolor}{RGB}{124.9, 255, 160.65}
\pgfplotsset{
compat=1.3,
width=10cm,
tick label style={font=\small},
label style={font=\small},
legend style={font=\small}
}

\usetikzlibrary{calc}
\usetikzlibrary{intersections} 

%%% START MACRO FOR ANNOTATION OF TRIANGLE WITH SLOPE %%%.
\newcommand{\logLogSlopeTriangle}[5]
{
    % #1. Relative offset in x direction.
    % #2. Width in x direction, so xA-xB.
    % #3. Relative offset in y direction.
    % #4. Slope d(y)/d(log10(x)).
    % #5. Plot options.

    \pgfplotsextra
    {
        \pgfkeysgetvalue{/pgfplots/xmin}{\xmin}
        \pgfkeysgetvalue{/pgfplots/xmax}{\xmax}
        \pgfkeysgetvalue{/pgfplots/ymin}{\ymin}
        \pgfkeysgetvalue{/pgfplots/ymax}{\ymax}

        % Calculate auxilliary quantities, in relative sense.
        \pgfmathsetmacro{\xArel}{#1}
        \pgfmathsetmacro{\yArel}{#3}
        \pgfmathsetmacro{\xBrel}{#1-#2}
        \pgfmathsetmacro{\yBrel}{\yArel}
        \pgfmathsetmacro{\xCrel}{\xArel}

        \pgfmathsetmacro{\lnxB}{\xmin*(1-(#1-#2))+\xmax*(#1-#2)} % in [xmin,xmax].
        \pgfmathsetmacro{\lnxA}{\xmin*(1-#1)+\xmax*#1} % in [xmin,xmax].
        \pgfmathsetmacro{\lnyA}{\ymin*(1-#3)+\ymax*#3} % in [ymin,ymax].
        \pgfmathsetmacro{\lnyC}{\lnyA+#4*(\lnxA-\lnxB)}
        \pgfmathsetmacro{\yCrel}{\lnyC-\ymin)/(\ymax-\ymin)} % THE IMPROVED EXPRESSION WITHOUT 'DIMENSION TOO LARGE' ERROR.

        % Define coordinates for \draw. MIND THE 'rel axis cs' as opposed to the 'axis cs'.
        \coordinate (A) at (rel axis cs:\xArel,\yArel);
        \coordinate (B) at (rel axis cs:\xBrel,\yBrel);
        \coordinate (C) at (rel axis cs:\xCrel,\yCrel);

        % Draw slope triangle.
        \draw[#5]   (A)-- node[pos=0.5,anchor=north] {}
                    (B)-- 
                    (C)-- node[pos=0.5,anchor=west] {#4}
                    cycle;
    }
}
%%% END MACRO FOR ANNOTATION OF TRIANGLE WITH SLOPE %%%.

\newcommand{\logLogSlopeTriangleNeg}[5]
{
    % #1. Relative offset in x direction.
    % #2. Width in x direction, so xA-xB.
    % #3. Relative offset in y direction.
    % #4. Slope d(y)/d(log10(x)).
    % #5. Plot options.

    \pgfplotsextra
    {
        \pgfkeysgetvalue{/pgfplots/xmin}{\xmin}
        \pgfkeysgetvalue{/pgfplots/xmax}{\xmax}
        \pgfkeysgetvalue{/pgfplots/ymin}{\ymin}
        \pgfkeysgetvalue{/pgfplots/ymax}{\ymax}

        % Calculate auxilliary quantities, in relative sense.
        \pgfmathsetmacro{\xArel}{#1}
        \pgfmathsetmacro{\yArel}{#3}
        \pgfmathsetmacro{\xBrel}{#1-#2}
        \pgfmathsetmacro{\yBrel}{\yArel}
        \pgfmathsetmacro{\xCrel}{\xArel}

        \pgfmathsetmacro{\lnxB}{\xmin*(1-(#1-#2))+\xmax*(#1-#2)} % in [xmin,xmax].
        \pgfmathsetmacro{\lnxA}{\xmin*(1-#1)+\xmax*#1} % in [xmin,xmax].
        \pgfmathsetmacro{\lnyA}{\ymin*(1-#3)+\ymax*#3} % in [ymin,ymax].
        \pgfmathsetmacro{\lnyC}{\lnyA+#4*(\lnxA-\lnxB)}
        \pgfmathsetmacro{\yCrel}{\lnyC-\ymin)/(\ymax-\ymin)} % THE IMPROVED EXPRESSION WITHOUT 'DIMENSION TOO LARGE' ERROR.

        % Define coordinates for \draw. MIND THE 'rel axis cs' as opposed to the 'axis cs'.
        \coordinate (A) at (rel axis cs:\xArel,\yArel);
        \coordinate (B) at (rel axis cs:\xBrel,\yBrel);
        \coordinate (C) at (rel axis cs:\xCrel,\yCrel);

        % Draw slope triangle.
        \draw[#5]   (A)-- node[pos=.5,anchor=south] {}
                    (B)-- 
                    (C)-- node[pos=0.5,anchor=west] {#4}
                    cycle;
    }
}
%%% END MACRO FOR ANNOTATION OF TRIANGLE WITH SLOPE %%%.

%%% START MACRO FOR ANNOTATION OF TRIANGLE WITH SLOPE %%%.
\newcommand{\logLogSlopeTriangleFlipNeg}[5]
{
    % #1. Relative offset in x direction.
    % #2. Width in x direction, so xA-xB.
    % #3. Relative offset in y direction.
    % #4. Slope d(y)/d(log10(x)).
    % #5. Plot options.

    \pgfplotsextra
    {
        \pgfkeysgetvalue{/pgfplots/xmin}{\xmin}
        \pgfkeysgetvalue{/pgfplots/xmax}{\xmax}
        \pgfkeysgetvalue{/pgfplots/ymin}{\ymin}
        \pgfkeysgetvalue{/pgfplots/ymax}{\ymax}

        % Calculate auxilliary quantities, in relative sense.
        %\pgfmathsetmacro{\xArel}{#1}
        %\pgfmathsetmacro{\yArel}{#3}
        \pgfmathsetmacro{\xBrel}{#1-#2}
        \pgfmathsetmacro{\yBrel}{#3}
        \pgfmathsetmacro{\xCrel}{#1}

        \pgfmathsetmacro{\lnxB}{\xmin*(1-(#1-#2))+\xmax*(#1-#2)} % in [xmin,xmax].
        \pgfmathsetmacro{\lnxA}{\xmin*(1-#1)+\xmax*#1} % in [xmin,xmax].
        \pgfmathsetmacro{\lnyA}{\ymin*(1-#3)+\ymax*#3} % in [ymin,ymax].
        \pgfmathsetmacro{\lnyC}{\lnyA+#4*(\lnxA-\lnxB)}
        \pgfmathsetmacro{\yCrel}{\lnyC-\ymin)/(\ymax-\ymin)} % THE IMPROVED EXPRESSION WITHOUT 'DIMENSION TOO LARGE' ERROR.

	\pgfmathsetmacro{\xArel}{\xBrel}
        \pgfmathsetmacro{\yArel}{\yCrel}

        % Define coordinates for \draw. MIND THE 'rel axis cs' as opposed to the 'axis cs'.
        \coordinate (A) at (rel axis cs:\xArel,\yArel);
        \coordinate (B) at (rel axis cs:\xBrel,\yBrel);
        \coordinate (C) at (rel axis cs:\xCrel,\yCrel);

        % Draw slope triangle.
        \draw[#5]   (A)-- node[pos=0.5,anchor=east] {#4}
                    (B)-- 
                    (C)-- node[pos=0.5,anchor=north] {1}
                    cycle;
    }
}
%%% END MACRO FOR ANNOTATION OF TRIANGLE WITH SLOPE %%%.


%%% START MACRO FOR ANNOTATION OF TRIANGLE WITH SLOPE %%%.
\newcommand{\logLogSlopeTriangleFlip}[5]
{
    % #1. Relative offset in x direction.
    % #2. Width in x direction, so xA-xB.
    % #3. Relative offset in y direction.
    % #4. Slope d(y)/d(log10(x)).
    % #5. Plot options.

    \pgfplotsextra
    {
        \pgfkeysgetvalue{/pgfplots/xmin}{\xmin}
        \pgfkeysgetvalue{/pgfplots/xmax}{\xmax}
        \pgfkeysgetvalue{/pgfplots/ymin}{\ymin}
        \pgfkeysgetvalue{/pgfplots/ymax}{\ymax}

        % Calculate auxilliary quantities, in relative sense.
        %\pgfmathsetmacro{\xArel}{#1}
        %\pgfmathsetmacro{\yArel}{#3}
        \pgfmathsetmacro{\xBrel}{#1-#2}
        \pgfmathsetmacro{\yBrel}{#3}
        \pgfmathsetmacro{\xCrel}{#1}

        \pgfmathsetmacro{\lnxB}{\xmin*(1-(#1-#2))+\xmax*(#1-#2)} % in [xmin,xmax].
        \pgfmathsetmacro{\lnxA}{\xmin*(1-#1)+\xmax*#1} % in [xmin,xmax].
        \pgfmathsetmacro{\lnyA}{\ymin*(1-#3)+\ymax*#3} % in [ymin,ymax].
        \pgfmathsetmacro{\lnyC}{\lnyA+#4*(\lnxA-\lnxB)}
        \pgfmathsetmacro{\yCrel}{\lnyC-\ymin)/(\ymax-\ymin)} % THE IMPROVED EXPRESSION WITHOUT 'DIMENSION TOO LARGE' ERROR.

	\pgfmathsetmacro{\xArel}{\xBrel}
        \pgfmathsetmacro{\yArel}{\yCrel}

        % Define coordinates for \draw. MIND THE 'rel axis cs' as opposed to the 'axis cs'.
        \coordinate (A) at (rel axis cs:\xArel,\yArel);
        \coordinate (B) at (rel axis cs:\xBrel,\yBrel);
        \coordinate (C) at (rel axis cs:\xCrel,\yCrel);

        % Draw slope triangle.
        \draw[#5]   (A)-- node[pos=0.5,anchor=east] {#4}
                    (B)-- 
                    (C)-- node[pos=0.5,anchor=south] {}
                    cycle;
    }
}
%%% END MACRO FOR ANNOTATION OF TRIANGLE WITH SLOPE %%%.


\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
\renewcommand{\floatpagefraction}{0.75}

\renewcommand{\hat}{\widehat}

\newcommand{\bbm}[1]{\mathbbm{#1}}
\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\equaldef}{\stackrel{\mathrm{def}}{=}}

\newcommand{\td}[2]{\frac{{\rm d}#1}{{\rm d}{\rm #2}}}
\newcommand{\pd}[2]{\frac{\partial#1}{\partial#2}}
\newcommand{\pdn}[3]{\frac{\partial^{#3}#1}{\partial#2^{#3}}}

\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}

\newcommand{\snor}[1]{\left| #1 \right|}
\newcommand{\nor}[1]{\left\| #1 \right\|}

\newcommand{\LRp}[1]{\left( #1 \right)}
\newcommand{\LRs}[1]{\left[ #1 \right]}
\newcommand{\LRa}[1]{\left\langle #1 \right\rangle}
\newcommand{\LRb}[1]{\left| #1 \right|}
\newcommand{\LRc}[1]{\left\{ #1 \right\}}
\newcommand{\LRceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\LRl}[1]{\left. #1 \right|}

\newcommand{\Grad} {\ensuremath{\nabla}}

\newcommand{\jump}[1] {\ensuremath{\llbracket#1\rrbracket}}
\newcommand{\avg}[1] {\ensuremath{\LRc{\!\{#1\}\!}}}

\newcommand{\LK}{L^2\LRp{D^k}}
\newcommand{\LdK}{L^2\LRp{\partial D^k}}
\renewcommand{\d}{\partial}
\newcommand{\Dhat}{\widehat{D}}
\newcommand{\Lhat}{L^2\LRp{\Dhat}}

\newcommand{\note}[1]{{\color{blue}{#1}}}

\newcommand*\diff[1]{\mathop{}\!{\mathrm{d}#1}} % d in integrand

\date{}
\author{Jesse Chan, Lucas Wilcox}
\title{Entropy stable notes}
\graphicspath{{./figs/}}


\begin{document}

\maketitle


\section{Curved meshes}

Assume non-affine geometric factors.  

Let $\bm{F}(\bm{U})$ denote the flux matrix whose rows are 
\[
\bm{F}(\bm{U}) = \LRp{
\begin{array}{c}
\bm{F}_x \\
\bm{F}_y
\end{array}
}.
\]
The conservation law of interest is the following
\[
\pd{\bm{U}}{t} + \Grad \cdot \bm{F}(\bm{U}) = 0,
\]
where the divergence is taken over each column of $\bm{F}(\bm{U})$.  

Let $\bm{G}$ denote the Jacobian of the geometric mapping
\[
\bm{G}_{ij} = \pd{\hat{\bm{x}}_j}{\bm{x}_i},
\]
and let $J$ denote the determinant of $\bm{G}$.  One can show that
\[
\hat{\Grad} \cdot \LRp{J\bm{G}^T} = 0  
\]
at the continuous level.  We also have that the mapped normals obey the property
\[
J\bm{G} \hat{\bm{n}}\hat{J}^f = \bm{n}J^f.
\]
At the continuous level, the physical gradient and divergence satisfy
\[
\LRp{\Grad u, \bm{v}}_{D^k} = \LRp{J\bm{G} \hat{\Grad} u,\bm{v}}_{\hat{D}}, \qquad \LRp{\Grad\cdot \bm{u},v}_{D^k} = \LRp{\hat{\Grad}\cdot \LRp{J\bm{G}^T u},\bm{v}}_{\hat{D}}, 
\]
as well as a corresponding integration by parts property.  

\section{Flux differencing}

Replace the flux derivative with
\[
\LRp{\Grad \cdot \bm{F}(\bm{U}),\bm{V}}_{D^k} \approx
\LRp{\LRl{\Grad \cdot \bm{F}_S(\bm{U}(\bm{x}),\bm{U}(\bm{x}'))}_{\bm{x}' = \bm{x}},\bm{V}}_{D^k}.
\]
It is possible to remove the effect of geometric aliasing by evaluating the above term via
\[
\LRp{\LRl{\hat{\Grad} \cdot \bm{F}^k_S(\bm{U}(\bm{x}),\bm{U}(\bm{x}'))}_{\bm{x}' = \bm{x}},\bm{V}}_{\hat{D}}, \qquad \bm{F}^k_S = \avg{J\bm{G}}\bm{F}_S\LRp{\bm{U}(\bm{x}),\bm{U}(\bm{x}')}
\]

%We can evaluate the new geometrically de-aliased flux using the discrete gradient of Chen and Shu
%\[
%\LRp{\Grad_h \cdot \bm{u},v}_{\Omega} = \sum_k \LRp{\hat{\Grad} \cdot J\bm{G}^T\Pi_N \bm{u},v }_{\hat{D}} + \frac{1}{2}\LRa{J\bm{G}^T\bm{u}^+ - \Pi_N J\bm{G}^T\bm{u}, v \hat{\bm{n}}}_{\d \hat{D}} + \frac{1}{2}\LRa{J\bm{G}^T\bm{u} - \Pi_N J\bm{G}^T\bm{u}, \Pi_N\LRp{v\hat{\bm{n}}}}_{\d \hat{D}}
%\]

Another alternative is to treat curvilinear grids using a skew-symmetric form, though this may not be strictly locally conservative.  

\subsection{Weight-adjusted DG}


We define the curvilinear $L^2$ projection $\Pi_N^J$ such that
\[
\LRp{\Pi_N^J u,v}_{D^k} = \LRp{J \Pi_N^J u,v}_{\hat{D}} = \LRp{uJ,v}_{\hat{D}} = \LRp{u,v}_{D^k}.  
\]
Let the weight-adjusted projection operator $P_N$ be defined as $P_N u = \Pi_N\LRp{\frac{1}{J}\Pi_N\LRp{uJ}}$.  Note that $P_N$ is self-adjoint with respect to the $J$-weighted $L^2$ inner product
\begin{align*}
\LRp{J P_N u, v} &= \LRp{\Pi_N\LRp{\frac{1}{J}\Pi_N\LRp{uJ}}, vJ} = \LRp{uJ, \Pi_N\LRp{\frac{1}{J}\Pi_N\LRp{vJ}}} =  \LRp{uJ, P_N v}.
\end{align*}

Let $\Pi_N^J u$ be the $L^2$ projection of $u$ with respect to the weighted (curvilinear) $L^2$ inner product.  We observe in numerical experiments that for a fixed geometric mapping, $\nor{\Pi_N^J u - P_N u}_{L^2\LRp{\Omega}} = O(h^{N+2})$.  Because the difference between the $L^2$ and WADG projection is superconvergent, the results are indistinguishable for a fixed geometric mapping.  

We can prove this bound using results from \cite{chan2016weight1}.  We first define the operator $T_{w}^{-1}$ as follows
\[
\LRp{wT_{w}^{-1} u,v}_{\hat{D}} = \LRp{ u,v}_{\hat{D}}, \qquad \forall v\in V_h.
\]
This forms the basis of the weight-adjusted approximation of weighted $L^2$ inner products.  The first theorem we need shows that $T_{1/J}^{-1}$ can be used to approximate weighted curvilinear $L^2$ inner products with order $(2N+2)$ accuracy.  
\begin{theorem}
\label{thm:moment}
Let $u\in W^{N+1,2}\LRp{D^k}$ and $v\in V_h\LRp{D^k}$.  Then, 
\begin{align*}
&\LRb{\LRp{u,vJ}_{\hat{D}} - \LRp{T^{-1}_{1/J}u,v}_{\hat{D}}} \leq \\
&Ch^{2N+2}\nor{J}_{L^{\infty}\LRp{D^k}}  \nor{\frac{1}{J}}_{L^{\infty}\LRp{D^k}}^2 \nor{J}^2_{W^{N+1,\infty}\LRp{D^k}}\nor{u}_{W^{N+1,2}\LRp{D^k}}\nor{v}_{W^{N+1,2}\LRp{D^k}}.
\end{align*}
\end{theorem}
\begin{proof}
The proof involves straightforward adaptations of Theorem 4, Theorem 5, and Theorem 6 in \cite{chan2016weight1} to the reference element $\hat{D}$.  
\end{proof}
The next result we need is a generalized inverse inequality.  
\begin{lemma}
\label{lemma:sobolev}
Let $v \in P^N\LRp{D^k}$, and let $h = {\rm diam}\LRp{D^k}$.  Then,
\[
\nor{v}_{W^{N+1,2}\LRp{D^k}} \leq C_{N} h^{-N} \nor{v}_{L^2\LRp{D^k}}.
\]
where $C_{N}$ is independent of $h$.
\end{lemma}
\begin{proof}
The result is the consequence of a scaling argument and a Rayleigh quotient bound involving the largest eigenvalue of the generalized eigenvalue problem  
\[
\bm{K}_N\bm{u} = \lambda\bm{M}\bm{u},
\]
where $\bm{M}$ is the $L^2$ mass matrix over $D^k$ and $\bm{K}_N$ is the Gram matrix corresponding to the Sobolev inner product for $W^{N+1,2}\LRp{D^k}$.  We note that the constant $C_N$ depends on the largest eigenvalue, which in turn depends on the order $N$ and dimension $d$.  
\end{proof}

We can now prove that $P_Nu$ is superconvergent to the curvilinear $L^2$ projection $\Pi^J_N u$
\begin{theorem}
Let $u \in W^{N+1,2}\LRp{D^k}$.  The difference between the $L^2$ projection $\Pi_Nu$ and the weight-adjusted projection $P_Nu$ is
\[
\nor{\Pi_N u - P_N u}_{L^2\LRp{D^k}} \leq C\nor{J}_{L^{\infty}\LRp{D^k}}  \nor{\frac{1}{J}}_{L^{\infty}\LRp{D^k}}^2 \nor{J}^2_{W^{N+1,\infty}\LRp{D^k}} h^{N+2}\nor{u}_{W^{N+1,2}\LRp{D^k}}.
\]
where $C$ is a mesh-independent constant.
\end{theorem}

\begin{proof}
Let $\Pi_N^J u$ be the $L^2$ projection over the curved element $D^k$, such that
\[
\LRp{J\Pi_N^J u,v} = \LRp{u J,v}, \qquad \forall v\in V_h.
\]
By definition, $P_N u$ satisfies a similar property
\[
\LRp{T_{1/J}^{-1} P_N u,v} = \LRp{u J,v}, \qquad \forall v\in V_h.
\]
Then, we have that
\[
\nor{\Pi_N^J  u - P_N u}_{L^2\LRp{D^k}}^2 = \LRp{\Pi_N^J  u - P_N u,vJ}_{\hat{D}}, \qquad v = \Pi_N^J  u - P_N u.
\]
Because $v \in P^N\LRp{D^k}$, we can also evaluate the squared error as
\begin{align*}
\nor{\Pi_N^J  u - P_N u}_{L^2\LRp{D^k}}^2 &= \LRb{\LRp{\Pi_N^J ,vJ}_{\hat{D}} - \LRp{P_N u,vJ}_{\hat{D}}}\\
& = \LRb{\LRp{u,vJ}_{\hat{D}} - \LRp{P_N u,vJ}_{\hat{D}}} = \LRb{\LRp{T_{1/J}^{-1}P_N u,v}_{\hat{D}} - \LRp{JP_N u,v}_{\hat{D}}}.
\end{align*}
Applying Theorem~\ref{thm:moment} and Lemma~\ref{lemma:sobolev} with $M=N$ then yields that 
\begin{align*}
\nor{\Pi_N u - P_N u}_{L^2\LRp{D^k}}^2 &\leq Ch^{2N+2} C_J\nor{u}_{W^{N+1,2}\LRp{D^k}}
\nor{v}_{W^{N+1,2}\LRp{\hat{D}}} \\
&\leq Ch^{N+2} C_J\nor{u}_{W^{N+1,2}\LRp{D^k}}\nor{v}_{L^2\LRp{D^k}},
\end{align*}
where $C_J$ is a mesh-independent constant depending on $J$.  Dividing through by 
\[
\nor{v}_{L^2\LRp{D^k}} = \nor{\Pi_N u - P_N u}_{L^2\LRp{D^k}}
\]
 gives the desired result.  % $C_J = \nor{J}_{L^{\infty}} \nor{\frac{1}{J}}^2_{L^\infty} \nor{J}^2_{W^{N+1,\infty}\LRp{\hat{D}}}$.
\end{proof}

\section{Limiting}

Ignoring high order terms in the Taylor expansion, we have
\[
u\LRp{\Pi_N v} - u = \pd{u}{v} \LRp{\Pi_Nv - v}.
\]
We want to limit $u$ with a compression towards the mean $u = \bar{u} + \theta(u-\bar{u})$ such that $\LRb{u\LRp{\Pi_N v}} \leq C\LRb{u}$.  

One option: ensure $\LRb{u\LRp{\Pi_N v} - u(\bar{v})} \approx \LRb{u - u(\bar{v})}$ based on Taylor series. 
\[
u\LRp{\Pi_N v} - u(\bar{v})
\]
Limit $\tilde{u} = \bar{u} + \theta(u-\bar{u})$ such that 
\[
\min \Pi_N v \geq \min v, \qquad \max \Pi_N v \leq \max v.
\]
Other options
\begin{itemize}
\item Adaptively choose time-step size?
\item Expensive option: bisection or Newton algorithm for finding theta.  
\end{itemize}



\bibliographystyle{unsrt}
\bibliography{dg}


\end{document}


